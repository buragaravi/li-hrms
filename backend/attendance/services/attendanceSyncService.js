/**
 * Attendance Sync Service
 * Handles syncing attendance logs from MSSQL to MongoDB
 * Processes raw logs and aggregates into daily records
 */

const AttendanceRawLog = require('../model/AttendanceRawLog');
const AttendanceDaily = require('../model/AttendanceDaily');
const AttendanceSettings = require('../model/AttendanceSettings');
const PreScheduledShift = require('../../shifts/model/PreScheduledShift');
const { fetchAttendanceLogsSQL } = require('../config/attendanceSQLHelper');
const Employee = require('../../employees/model/Employee');
const OD = require('../../leaves/model/OD');
const { detectAndAssignShift } = require('../../shifts/services/shiftDetectionService');
const { detectExtraHours } = require('./extraHoursService');
const Settings = require('../../settings/model/Settings');

const MAX_PAIRING_WINDOW_HOURS = 25; // Maximum allowed duration for a shift (prevents multi-day jumps)

/**
 * Format date to YYYY-MM-DD
 */
const formatDate = (date) => {
  const d = new Date(date);
  return `${d.getFullYear()}-${String(d.getMonth() + 1).padStart(2, '0')}-${String(d.getDate()).padStart(2, '0')}`;
};

/**
 * Process raw logs and aggregate into daily records
 * NEW APPROACH: Process logs chronologically to correctly pair IN/OUT across days
 * @param {Array} rawLogs - Array of raw log objects
 * @param {Boolean} previousDayLinking - Whether to enable previous day linking (deprecated, using chronological approach)
 * @returns {Object} Statistics of processed records
 */
const processAndAggregateLogs = async (rawLogs, previousDayLinking = false, skipInsertion = false) => {
  const stats = {
    rawLogsInserted: 0,
    rawLogsSkipped: 0,
    dailyRecordsCreated: 0,
    dailyRecordsUpdated: 0,
    errors: [],
  };

  try {
    // Fetch global general settings (for grace periods, etc.)
    const generalConfig = await Settings.getSettingsByCategory('general');

    // First, insert all raw logs (Duplicate prevention)
    // SKIP if explicitly requested (e.g. from RealTime Controller which already saves)
    if (!skipInsertion) {
      for (const log of rawLogs) {
        try {
          const date = formatDate(log.timestamp);
          const logData = {
            employeeNumber: log.employeeNumber,
            timestamp: new Date(log.timestamp),
            type: log.type,
            source: log.source || 'mssql',
            date: date,
            rawData: log.rawData,
          };

          // Try to insert (will fail if duplicate due to unique index)
          try {
            await AttendanceRawLog.create(logData);
            stats.rawLogsInserted++;
          } catch (error) {
            if (error.code === 11000) {
              // Duplicate - skip
              stats.rawLogsSkipped++;
            } else {
              throw error;
            }
          }
        } catch (error) {
          stats.errors.push(`Error processing log for ${log.employeeNumber}: ${error.message}`);
        }
      }
    }


    // NEW APPROACH: Group logs by employee, then process chronologically
    const logsByEmployee = {};

    // Fetch all logs for employees involved (to get complete picture across days)
    const employeeNumbers = [...new Set(rawLogs.map(log => log.employeeNumber.toUpperCase()))];

    for (const empNo of employeeNumbers) {
      // Get all logs for this employee from database (chronologically sorted)
      // We need a date range - use the dates from rawLogs
      const dates = [...new Set(rawLogs.filter(l => l.employeeNumber.toUpperCase() === empNo).map(l => formatDate(l.timestamp)))];
      const minDate = dates.sort()[0];
      const maxDate = dates.sort()[dates.length - 1];

      // Extend range by 1 day on each side to catch overnight shifts
      const minDateObj = new Date(minDate);
      minDateObj.setDate(minDateObj.getDate() - 1);
      const maxDateObj = new Date(maxDate);
      maxDateObj.setDate(maxDateObj.getDate() + 1);

      const allLogs = await AttendanceRawLog.find({
        employeeNumber: empNo,
        date: {
          $gte: formatDate(minDateObj),
          $lte: formatDate(maxDateObj),
        },
        timestamp: { $gte: new Date('2020-01-01') }, // Ignore ancient logs (1899/1900)
        type: { $in: ['IN', 'OUT'] }, // CRITICAL: Only process IN/OUT logs, exclude null-type (BREAK/OT)
      }).sort({ timestamp: 1 }); // Sort chronologically

      logsByEmployee[empNo] = allLogs.map(log => ({
        timestamp: new Date(log.timestamp),
        type: log.type,
        _id: log._id,
      }));
    }

    // NEW APPROACH: Process logs using Multi-Shift Engine
    const { processMultiShiftAttendance } = require('./multiShiftProcessingService');

    for (const [employeeNumber, logs] of Object.entries(logsByEmployee)) {
      try {
        // Group logs by date for this employee
        const logsByDate = {};
        for (const log of logs) {
          const date = formatDate(log.timestamp);
          if (!logsByDate[date]) logsByDate[date] = [];
          logsByDate[date].push(log);
        }

        // Process each date that has regular logs
        for (const date of Object.keys(logsByDate)) {
          console.log(`[SyncService] Processing Multi-Shift: Emp=${employeeNumber}, Date=${date}`);

          const result = await processMultiShiftAttendance(
            employeeNumber,
            date,
            logs, // Pass ALL logs for cross-day context
            generalConfig
          );

          if (result.success) {
            // Stats tracking
            if (result.isNew) stats.dailyRecordsCreated++;
            else stats.dailyRecordsUpdated++;
          } else {
            stats.errors.push(`${employeeNumber} on ${date}: ${result.reason || result.error || 'Failed'}`);
          }
        }
      } catch (error) {
        stats.errors.push(`Error processing employee ${employeeNumber}: ${error.message}`);
      }
    }

    return stats;
  } catch (error) {
    stats.errors.push(`Error in processAndAggregateLogs: ${error.message}`);
    return stats;
  }
};

/**
 * Apply previous day linking heuristic
 * If previous day has 1 log and current day has 1 log, link them
 */
const applyPreviousDayLinking = async (logsByEmployeeAndDate) => {
  // This is a simplified version - can be enhanced
  // For now, we'll mark these for admin review if needed
  // The actual linking logic can be more complex based on shift times
  // TODO: Implement full previous day linking logic
};

/**
 * Sync attendance from MSSQL to MongoDB
 * @param {Date} fromDate - Start date (optional, defaults to last 7 days)
 * @param {Date} toDate - End date (optional, defaults to today)
 * @returns {Object} Sync statistics
 */
const syncAttendanceFromMSSQL = async (fromDate = null, toDate = null) => {
  const stats = {
    success: false,
    rawLogsFetched: 0,
    rawLogsInserted: 0,
    rawLogsSkipped: 0,
    dailyRecordsCreated: 0,
    dailyRecordsUpdated: 0,
    errors: [],
    message: '',
  };

  try {
    // Get settings
    const settings = await AttendanceSettings.getSettings();

    if (settings.dataSource !== 'mssql') {
      throw new Error('Data source is not set to MSSQL');
    }

    if (!settings.mssqlConfig.databaseName || !settings.mssqlConfig.tableName) {
      throw new Error('MSSQL configuration is incomplete');
    }

    // Set default date range if not provided
    if (!fromDate) {
      fromDate = new Date();
      fromDate.setDate(fromDate.getDate() - 7); // Last 7 days
    }
    if (!toDate) {
      toDate = new Date();
    }

    // Fetch logs from MSSQL
    const rawLogs = await fetchAttendanceLogsSQL(settings, fromDate, toDate);
    stats.rawLogsFetched = rawLogs.length;

    if (rawLogs.length === 0) {
      stats.message = 'No logs found in MSSQL for the specified date range';
      stats.success = true;
      return stats;
    }

    // Process and aggregate
    const processStats = await processAndAggregateLogs(
      rawLogs,
      settings.previousDayLinking?.enabled || false
    );

    stats.rawLogsInserted = processStats.rawLogsInserted;
    stats.rawLogsSkipped = processStats.rawLogsSkipped;
    stats.dailyRecordsCreated = processStats.dailyRecordsCreated;
    stats.dailyRecordsUpdated = processStats.dailyRecordsUpdated;
    stats.errors = processStats.errors;

    // Update sync status in settings
    await AttendanceSettings.findOneAndUpdate(
      {},
      {
        $set: {
          'syncSettings.lastSyncAt': new Date(),
          'syncSettings.lastSyncStatus': stats.errors.length > 0 ? 'failed' : 'success',
          'syncSettings.lastSyncMessage': stats.errors.length > 0
            ? `Sync completed with ${stats.errors.length} errors`
            : `Successfully synced ${stats.rawLogsInserted} logs`,
        },
      }
    );

    stats.success = true;
    stats.message = `Successfully synced ${stats.rawLogsInserted} logs, created ${stats.dailyRecordsCreated} daily records, updated ${stats.dailyRecordsUpdated} records`;

  } catch (error) {
    stats.success = false;
    stats.errors.push(error.message);
    stats.message = `Sync failed: ${error.message}`;

    // Update sync status
    try {
      await AttendanceSettings.findOneAndUpdate(
        {},
        {
          $set: {
            'syncSettings.lastSyncAt': new Date(),
            'syncSettings.lastSyncStatus': 'failed',
            'syncSettings.lastSyncMessage': error.message,
          },
        }
      );
    } catch (updateError) {
      // Ignore update error
    }
  }

  return stats;
};

module.exports = {
  syncAttendanceFromMSSQL,
  processAndAggregateLogs,
  formatDate,
};

